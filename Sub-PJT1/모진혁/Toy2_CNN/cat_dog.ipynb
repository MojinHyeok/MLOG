{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cat&dog.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP1e4uTEZ9MaEb5X94efHeH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"X3GNTQOl82gl"},"source":["import os\n","\n","os.environ['KAGGLE_CONFIG_DIR']= '/content/'\n","!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tc8Yy9EgC_6B"},"source":["!unzip -q train.zip -d ."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ANxhQFtuszAN","executionInfo":{"status":"ok","timestamp":1630388049137,"user_tz":-540,"elapsed":474,"user":{"displayName":"모진혁","photoUrl":"","userId":"10136984405099208071"}}},"source":["%rm -rf dataset"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"TZ26V5gLkb1m","executionInfo":{"status":"ok","timestamp":1630388062872,"user_tz":-540,"elapsed":10726,"user":{"displayName":"모진혁","photoUrl":"","userId":"10136984405099208071"}}},"source":["import os\n","import tensorflow as tf\n","import shutil\n","#1.일단 train 안의 모든 파일명을 출력해보고 \n","#2. 파일명에 cat이 들어있다면 dataset의cat폴더로\n","#3. 파일명에 dog 들어있다면 dataset의 dog폴더로\n","os.mkdir('/content/dataset')\n","os.mkdir('/content/dataset/cat')\n","os.mkdir('/content/dataset/dog')\n","\n","for i in os.listdir('/content/train'):\n","  if 'cat' in i:\n","    shutil.copyfile('/content/train/'+i,'/content/dataset/cat/'+i) \n","  if 'dog' in i:\n","    shutil.copyfile('/content/train/'+i,'/content/dataset/dog/'+i)    \n"," \n"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V_bEBaB5nPhq","executionInfo":{"status":"ok","timestamp":1630399269091,"user_tz":-540,"elapsed":1155683,"user":{"displayName":"모진혁","photoUrl":"","userId":"10136984405099208071"}},"outputId":"8c33b0b5-4c6c-496b-e0ea-4558e9a73333"},"source":["import tensorflow as tf\n","#애는 데이터 중 80%\n","train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    '/content/dataset',\n","    image_size=(64,64),\n","    batch_size=64,\n","    subset='training',\n","    validation_split=0.2,#20#만큼 검증데이터로 나타남\n","    seed=1234\n",")\n","#애는 데이터중 20%\n","val_ds=tf.keras.preprocessing.image_dataset_from_directory(\n","    '/content/dataset',\n","    image_size=(64,64),\n","    batch_size=64,\n","    subset='validation',\n","    validation_split=0.2,\n","    seed=1234\n",")\n","\n","\n","def 전처리함수(i,정답):\n","  i = tf.cast(i/255.0,tf.float32)\n","  return i,정답\n","\n","train_ds=train_ds.map(전처리함수)\n","val_ds=val_ds.map(전처리함수)\n","\n","model=tf.keras.Sequential([\n","    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal',input_shape=(64,64,3)),#뒤집어주세요\n","    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n","    tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n","    tf.keras.layers.Conv2D(32,(3,3),padding=\"same\",activation='relu'),#color사진이라 input의 마지막은 3\n","    tf.keras.layers.MaxPooling2D((2,2)),#풀링사이즈 2,2\n","    tf.keras.layers.Conv2D(64,(3,3),padding=\"same\",activation='relu'),\n","    tf.keras.layers.MaxPooling2D((2,2)),#풀링사이즈 2,2\n","    tf.keras.layers.Dropout(0.2),#overfitting 완화기능(학습용 데이터를 외워버리는걸 방지) 윗레이어의 노드를 일부제거\n","    tf.keras.layers.Conv2D(128,(3,3),padding=\"same\",activation='relu'),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(128, activation=\"relu\"),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n","])\n","model.summary()\n","\n","\n","model.compile( loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n","model.fit(train_ds, validation_data=val_ds, epochs=5)"],"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 25000 files belonging to 2 classes.\n","Using 20000 files for training.\n","Found 25000 files belonging to 2 classes.\n","Using 5000 files for validation.\n","Model: \"sequential_38\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","random_flip_9 (RandomFlip)   (None, 64, 64, 3)         0         \n","_________________________________________________________________\n","random_rotation_8 (RandomRot (None, 64, 64, 3)         0         \n","_________________________________________________________________\n","random_zoom_8 (RandomZoom)   (None, 64, 64, 3)         0         \n","_________________________________________________________________\n","conv2d_114 (Conv2D)          (None, 64, 64, 32)        896       \n","_________________________________________________________________\n","max_pooling2d_114 (MaxPoolin (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_115 (Conv2D)          (None, 32, 32, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d_115 (MaxPoolin (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","dropout_76 (Dropout)         (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv2d_116 (Conv2D)          (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","max_pooling2d_116 (MaxPoolin (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","flatten_38 (Flatten)         (None, 8192)              0         \n","_________________________________________________________________\n","dense_76 (Dense)             (None, 128)               1048704   \n","_________________________________________________________________\n","dropout_77 (Dropout)         (None, 128)               0         \n","_________________________________________________________________\n","dense_77 (Dense)             (None, 1)                 129       \n","=================================================================\n","Total params: 1,142,081\n","Trainable params: 1,142,081\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/5\n","313/313 [==============================] - 238s 752ms/step - loss: 0.6294 - accuracy: 0.6408 - val_loss: 0.5669 - val_accuracy: 0.7074\n","Epoch 2/5\n","313/313 [==============================] - 227s 723ms/step - loss: 0.5493 - accuracy: 0.7189 - val_loss: 0.6025 - val_accuracy: 0.6888\n","Epoch 3/5\n","313/313 [==============================] - 230s 734ms/step - loss: 0.5044 - accuracy: 0.7490 - val_loss: 0.5367 - val_accuracy: 0.7284\n","Epoch 4/5\n","313/313 [==============================] - 229s 729ms/step - loss: 0.4818 - accuracy: 0.7730 - val_loss: 0.4458 - val_accuracy: 0.7926\n","Epoch 5/5\n","313/313 [==============================] - 230s 733ms/step - loss: 0.4544 - accuracy: 0.7847 - val_loss: 0.5382 - val_accuracy: 0.7432\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f3f5d8de210>"]},"metadata":{},"execution_count":69}]}]}